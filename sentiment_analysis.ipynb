{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Sentiment Analysis Experiments\n\nGoal: predict `sentiment` (positive/neutral/negative) from learner feedback. We escalate from classic ML baselines to advanced transformers and agentic LLM workflows, with explainability, research-ethics checks, and error analysis."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "import pandas as pd\nfrom pathlib import Path\n\nDATA_PATH = Path('data_feedback.xlsx')\ndf = pd.read_excel(DATA_PATH)\ndf.head()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 1. Data audit and ethics guardrails\n- **PII scan:** quick heuristic scan to avoid leaking names; expand with policy-based filters for real deployments.\n- **Bias check:** review label balance and text length distribution to avoid overfitting to overly positive feedback.\n- **Consent note:** ensure data use follows institutional review guidelines before training or sharing models."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Quick descriptive stats\nlabel_counts = df['sentiment'].value_counts()\nlengths = df['comments'].str.len()\nlabel_counts, lengths.describe()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 2. Baseline: TF\u2013IDF + Linear Models\nRationale: fast, transparent, and establishes a sanity-check benchmark before using heavier models."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import classification_report\n\nX_train, X_val, y_train, y_val = train_test_split(df['comments'], df['sentiment'], test_size=0.2, stratify=df['sentiment'], random_state=42)\n\ntfidf_lr = Pipeline([('tfidf', TfidfVectorizer(ngram_range=(1,2), min_df=1)), ('clf', LogisticRegression(max_iter=200, class_weight='balanced'))])\ntfidf_lr.fit(X_train, y_train)\ny_pred = tfidf_lr.predict(X_val)\nprint(classification_report(y_val, y_pred))"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Explainability for baseline\nUse SHAP/LIME to identify influential n-grams driving predictions."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Example with LIME (install if needed)\n# from lime.lime_text import LimeTextExplainer\n# explainer = LimeTextExplainer(class_names=tfidf_lr.classes_)\n# exp = explainer.explain_instance(X_val.iloc[0], tfidf_lr.predict_proba, num_features=8)\n# exp.show_in_notebook()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 3. Intermediate: Classical + Character Features\nRationale: character n-grams add robustness to misspellings and colloquial phrases."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from sklearn.feature_extraction.text import TfidfVectorizer as CharTfidf\nchar_tfidf_lr = Pipeline([('tfidf', CharTfidf(analyzer='char', ngram_range=(3,5), min_df=1)), ('clf', LogisticRegression(max_iter=200, class_weight='balanced'))])\nchar_tfidf_lr.fit(X_train, y_train)\nprint(classification_report(y_val, char_tfidf_lr.predict(X_val)))"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 4. Advanced: Transformer Fine-tuning\nRationale: contextual embeddings capture nuanced sentiment cues.\n- **Model:** `distilbert-base-uncased` or similar.\n- **Tricks:** class weights, freeze lower layers for small data, early stopping.\n- **Evaluation:** macro-F1, calibration curves for threshold tuning."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Skeleton; uncomment to run in GPU environment\n# from datasets import Dataset\n# from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n# model_name = 'distilbert-base-uncased'\n# tokenizer = AutoTokenizer.from_pretrained(model_name)\n# dataset = Dataset.from_pandas(df[['comments', 'sentiment']])\n# label2id = {lbl:i for i,lbl in enumerate(sorted(df['sentiment'].unique()))}\n# id2label = {i:lbl for lbl,i in label2id.items()}\n# dataset = dataset.map(lambda x: {'labels': label2id[x['sentiment']]}, remove_columns=['sentiment'])\n# dataset = dataset.map(lambda x: tokenizer(x['comments'], truncation=True), batched=True)\n# model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(label2id), id2label=id2label, label2id=label2id)\n# args = TrainingArguments(output_dir='./sentiment-model', num_train_epochs=6, per_device_train_batch_size=16, per_device_eval_batch_size=32, learning_rate=2e-5, weight_decay=0.01, evaluation_strategy='epoch', load_best_model_at_end=True)\n# trainer = Trainer(model=model, args=args, train_dataset=dataset, eval_dataset=dataset, tokenizer=tokenizer)\n# trainer.train()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Transformer explainability\n- Integrated gradients or SHAP on transformer outputs to surface token saliency.\n- Contrast LIME explanations between the TF\u2013IDF baseline and the transformer."
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 5. Agentic LLM workflow\nRationale: leverage instruction-tuned LLM with chain-of-thought + self-consistency for low-data regimes.\n- Prompt template enforces JSON output and short rationale.\n- Add uncertainty scoring via disagreement across temperature-sampled responses.\n- Guardrails: content filters to avoid unsafe generations and ensure privacy."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Pseudocode placeholder for LLM inference\n# def llm_sentiment_predict(text):\n#     prompt = f\"Classify sentiment (positive/neutral/negative) for: {text}. Return JSON with label and short rationale.\"\n#     # call open-source model or API here\n#     return {'label': 'positive', 'rationale': 'praise words'}"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 6. Error analysis & ethics review\n- Build a **mistake notebook**: list misclassifications with text, predicted vs. gold, and attribution highlights.\n- Examine failures by length buckets and by topic (teacher vs. course) to detect bias.\n- Document ethical considerations: avoid overclaiming accuracy, respect consent, and minimize harm when providing automated feedback."
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 5
}