{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Teacher vs Course Classification\n",
        "\n",
        "Heuristics, baselines, transformers, robustness checks, and prompting for topic detection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "DATA_PATH = Path(\"data_feedback.xlsx\")\n",
        "RANDOM_SEED = 7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load and inspect"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df = pd.read_excel(DATA_PATH).rename(columns={\"teacher/course\": \"topic\"})\n",
        "print(df.head())\n",
        "print(df[\"topic\"].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Split and helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "train_df, val_df = train_test_split(df, test_size=0.25, stratify=df[\"topic\"], random_state=RANDOM_SEED)\n",
        "\n",
        "def evaluate(model, x_train, y_train, x_val, y_val, label):\n",
        "    model.fit(x_train, y_train)\n",
        "    preds = model.predict(x_val)\n",
        "    print(f\"=== {label} ===\")\n",
        "    print(classification_report(y_val, preds))\n",
        "    cm = confusion_matrix(y_val, preds, labels=sorted(y_val.unique()))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=sorted(y_val.unique()), yticklabels=sorted(y_val.unique()))\n",
        "    plt.title(label)\n",
        "    plt.xlabel(\"Pred\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.show()\n",
        "    return preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Heuristic baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def heuristic_classifier(text):\n",
        "    t = text.lower()\n",
        "    if any(k in t for k in [\"teacher\", \"sir\", \"madam\", \"he\", \"she\"]):\n",
        "        return \"teacher\"\n",
        "    if any(k in t for k in [\"course\", \"curriculum\", \"practical\", \"syllabus\"]):\n",
        "        return \"course\"\n",
        "    return \"teacher\"\n",
        "heuristic_preds = val_df[\"comments\"].apply(heuristic_classifier)\n",
        "print(classification_report(val_df[\"topic\"], heuristic_preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. TF-IDF baselines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "word_clf = Pipeline([(\"tfidf\", TfidfVectorizer(ngram_range=(1,2))), (\"clf\", LogisticRegression(max_iter=1000, class_weight=\"balanced\"))])\n",
        "_ = evaluate(word_clf, train_df[\"comments\"], train_df[\"topic\"], val_df[\"comments\"], val_df[\"topic\"], \"Word TF-IDF\")\n",
        "char_clf = Pipeline([(\"tfidf\", TfidfVectorizer(analyzer=\"char\", ngram_range=(3,5))), (\"clf\", LogisticRegression(max_iter=500, class_weight=\"balanced\"))])\n",
        "_ = evaluate(char_clf, train_df[\"comments\"], train_df[\"topic\"], val_df[\"comments\"], val_df[\"topic\"], \"Char TF-IDF\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Sentiment-prefixed robustness check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sent_pref_train = [f\"[SENT={s}] {c}\" for s, c in zip(train_df[\"sentiment\"], train_df[\"comments\"])]\n",
        "sent_pref_val = [f\"[SENT={s}] {c}\" for s, c in zip(val_df[\"sentiment\"], val_df[\"comments\"])]\n",
        "_ = evaluate(word_clf, sent_pref_train, train_df[\"topic\"], sent_pref_val, val_df[\"topic\"], \"Sentiment-prefixed TF-IDF\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Transformer fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "label2id = {l:i for i,l in enumerate(sorted(df[\"topic\"].unique()))}\n",
        "id2label = {i:l for l,i in label2id.items()}\n",
        "def tok(batch):\n",
        "    return tokenizer(batch[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
        "train_ds = Dataset.from_dict({\"text\": train_df[\"comments\"].tolist(), \"label\": [label2id[x] for x in train_df[\"topic\"]]})\n",
        "val_ds = Dataset.from_dict({\"text\": val_df[\"comments\"].tolist(), \"label\": [label2id[x] for x in val_df[\"topic\"]]})\n",
        "train_ds = train_ds.map(tok, batched=True)\n",
        "val_ds = val_ds.map(tok, batched=True)\n",
        "train_ds.set_format(\"torch\")\n",
        "val_ds.set_format(\"torch\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(label2id), id2label=id2label, label2id=label2id)\n",
        "args = TrainingArguments(output_dir=\"./topic_distilbert\", evaluation_strategy=\"epoch\", save_strategy=\"epoch\", num_train_epochs=5, per_device_train_batch_size=8, per_device_eval_batch_size=16, learning_rate=2e-5, weight_decay=0.01, logging_steps=10)\n",
        "trainer = Trainer(model=model, args=args, train_dataset=train_ds, eval_dataset=val_ds, tokenizer=tokenizer)\n",
        "# trainer.train()\n",
        "# trainer.evaluate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Sentiment-shift stress (train positive only)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "positive_df = df[df[\"sentiment\"] == \"positive\"]\n",
        "shift_train, shift_val = train_test_split(positive_df, test_size=0.3, stratify=positive_df[\"topic\"], random_state=RANDOM_SEED)\n",
        "shift_clf = Pipeline([(\"tfidf\", TfidfVectorizer(ngram_range=(1,2))), (\"clf\", LogisticRegression(max_iter=1000, class_weight=\"balanced\"))])\n",
        "shift_clf.fit(shift_train[\"comments\"], shift_train[\"topic\"])\n",
        "robust_preds = shift_clf.predict(val_df[\"comments\"])\n",
        "print(classification_report(val_df[\"topic\"], robust_preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Prompting baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from transformers import pipeline\n",
        "prompt_template = \"Is this feedback about the teacher or the course? Respond with teacher or course only. Text: {text}\"\n",
        "zero_shot = pipeline(\"text-classification\", model=\"facebook/bart-large-mnli\")\n",
        "print(zero_shot(prompt_template.format(text=val_df.iloc[0][\"comments\"])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Error analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def collect_errors(model, x_val, y_val):\n",
        "    preds = model.predict(x_val)\n",
        "    return pd.DataFrame({\"text\": x_val, \"true\": y_val, \"pred\": preds}).query(\"true != pred\")\n",
        "err_df = collect_errors(word_clf, val_df[\"comments\"], val_df[\"topic\"])\n",
        "err_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. CLI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import argparse\n",
        "\n",
        "def run_cli():\n",
        "    parser = argparse.ArgumentParser(description=\"Teacher vs Course classification\")\n",
        "    parser.add_argument(\"--use_sentiment_prefix\", action=\"store_true\")\n",
        "    args = parser.parse_args(args=[])\n",
        "    x_train = train_df[\"comments\"] if not args.use_sentiment_prefix else sent_pref_train\n",
        "    x_val = val_df[\"comments\"] if not args.use_sentiment_prefix else sent_pref_val\n",
        "    model = Pipeline([(\"tfidf\", TfidfVectorizer(ngram_range=(1,2))), (\"clf\", LogisticRegression(max_iter=1000, class_weight=\"balanced\"))])\n",
        "    evaluate(model, x_train, train_df[\"topic\"], x_val, val_df[\"topic\"], \"CLI run\")\n",
        "\n",
        "# run_cli()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}