{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Aspect Classification for Educational Feedback\n",
        "\n",
        "Covers baselines, transformers, prompting, cross-domain checks, and error analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "DATA_PATH = Path(\"data_feedback.xlsx\")\n",
        "RANDOM_SEED = 13"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load data and glossary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ASPECT_GLOSSARY = {\"teaching skills\": \"Ability to deliver content clearly and effectively.\", \"behaviour\": \"Professionalism, politeness, and supportiveness.\", \"knowledge\": \"Depth of subject-matter expertise.\", \"relevancy\": \"Fit between course content and learner needs.\", \"general\": \"General praise/critique without specific focus.\"}\n",
        "df = pd.read_excel(DATA_PATH).rename(columns={\"teacher/course\": \"topic\"})\n",
        "print(df.head())\n",
        "print(\"\n",
        "Aspect counts:\n",
        "\", df[\"aspect\"].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Split and helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "train_df, val_df = train_test_split(df, test_size=0.25, stratify=df[\"aspect\"], random_state=RANDOM_SEED)\n",
        "\n",
        "def evaluate(model, x_train, y_train, x_val, y_val, label):\n",
        "    model.fit(x_train, y_train)\n",
        "    preds = model.predict(x_val)\n",
        "    print(f\"=== {label} ===\")\n",
        "    print(classification_report(y_val, preds))\n",
        "    cm = confusion_matrix(y_val, preds, labels=sorted(y_val.unique()))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=sorted(y_val.unique()), yticklabels=sorted(y_val.unique()))\n",
        "    plt.title(label)\n",
        "    plt.xlabel(\"Pred\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.show()\n",
        "    return preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. TF-IDF baselines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "word_clf = Pipeline([(\"tfidf\", TfidfVectorizer(ngram_range=(1,2))), (\"clf\", LogisticRegression(max_iter=1000, class_weight=\"balanced\"))])\n",
        "_ = evaluate(word_clf, train_df[\"comments\"], train_df[\"aspect\"], val_df[\"comments\"], val_df[\"aspect\"], \"Word TF-IDF\")\n",
        "char_clf = Pipeline([(\"tfidf\", TfidfVectorizer(analyzer=\"char\", ngram_range=(3,5))), (\"clf\", LogisticRegression(max_iter=500, class_weight=\"balanced\"))])\n",
        "_ = evaluate(char_clf, train_df[\"comments\"], train_df[\"aspect\"], val_df[\"comments\"], val_df[\"aspect\"], \"Char TF-IDF\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Topic-prefixed variant"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def add_topic_prefix(texts, topics):\n",
        "    return [f\"[TOPIC={t}] {txt}\" for t, txt in zip(topics, texts)]\n",
        "pref_train = add_topic_prefix(train_df[\"comments\"], train_df[\"topic\"])\n",
        "pref_val = add_topic_prefix(val_df[\"comments\"], val_df[\"topic\"])\n",
        "_ = evaluate(word_clf, pref_train, train_df[\"aspect\"], pref_val, val_df[\"aspect\"], \"Topic-prefixed TF-IDF\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Sentence-embedding classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "embedder = SentenceTransformer(\"all-mpnet-base-v2\")\n",
        "train_vecs = embedder.encode(train_df[\"comments\"].tolist(), show_progress_bar=False)\n",
        "val_vecs = embedder.encode(val_df[\"comments\"].tolist(), show_progress_bar=False)\n",
        "embed_clf = LogisticRegression(max_iter=1000, class_weight=\"balanced\")\n",
        "embed_clf.fit(train_vecs, train_df[\"aspect\"])\n",
        "preds = embed_clf.predict(val_vecs)\n",
        "print(classification_report(val_df[\"aspect\"], preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Transformer fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "label2id = {l:i for i,l in enumerate(sorted(df[\"aspect\"].unique()))}\n",
        "id2label = {i:l for l,i in label2id.items()}\n",
        "def tok(batch):\n",
        "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "train_ds = Dataset.from_dict({\"text\": train_df[\"comments\"].tolist(), \"label\": [label2id[x] for x in train_df[\"aspect\"]]})\n",
        "val_ds = Dataset.from_dict({\"text\": val_df[\"comments\"].tolist(), \"label\": [label2id[x] for x in val_df[\"aspect\"]]})\n",
        "train_ds = train_ds.map(tok, batched=True)\n",
        "val_ds = val_ds.map(tok, batched=True)\n",
        "train_ds.set_format(\"torch\")\n",
        "val_ds.set_format(\"torch\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(label2id), id2label=id2label, label2id=label2id)\n",
        "args = TrainingArguments(output_dir=\"./aspect_distilbert\", evaluation_strategy=\"epoch\", save_strategy=\"epoch\", num_train_epochs=5, per_device_train_batch_size=8, per_device_eval_batch_size=16, learning_rate=2e-5, weight_decay=0.01, logging_steps=10)\n",
        "trainer = Trainer(model=model, args=args, train_dataset=train_ds, eval_dataset=val_ds, tokenizer=tokenizer)\n",
        "# trainer.train()\n",
        "# trainer.evaluate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Cross-domain/generalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "teacher_df = df[df[\"topic\"] == \"teacher\"]\n",
        "course_df = df[df[\"topic\"] == \"course\"]\n",
        "sub_clf = Pipeline([(\"tfidf\", TfidfVectorizer(ngram_range=(1,2))), (\"clf\", LogisticRegression(max_iter=1000, class_weight=\"balanced\"))])\n",
        "sub_clf.fit(teacher_df[\"comments\"], teacher_df[\"aspect\"])\n",
        "transfer_preds = sub_clf.predict(course_df[\"comments\"])\n",
        "print(classification_report(course_df[\"aspect\"], transfer_preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Prompting baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "def build_prompt(row):\n",
        "    glossary = ' '.join([f\"{k}: {v}\" for k, v in ASPECT_GLOSSARY.items()])\n",
        "    return f\"Given the following aspect definitions: {glossary}. Choose the best aspect for: {row['comments']}\"\n",
        "\n",
        "prompts = val_df.apply(build_prompt, axis=1)\n",
        "zero_shot = pipeline('text-classification', model='facebook/bart-large-mnli')\n",
        "print(zero_shot(prompts.iloc[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Error analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def collect_errors(model, x_val, y_val):\n",
        "    preds = model.predict(x_val)\n",
        "    return pd.DataFrame({\"text\": x_val, \"true\": y_val, \"pred\": preds}).query(\"true != pred\")\n",
        "err_df = collect_errors(word_clf, val_df[\"comments\"], val_df[\"aspect\"])\n",
        "err_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. CLI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import argparse\n",
        "\n",
        "def run_cli():\n",
        "    parser = argparse.ArgumentParser(description=\"Aspect classification baseline\")\n",
        "    parser.add_argument(\"--use_topic\", action=\"store_true\", help=\"prepend topic tags\")\n",
        "    args = parser.parse_args(args=[])\n",
        "    x_train = train_df[\"comments\"] if not args.use_topic else add_topic_prefix(train_df[\"comments\"], train_df[\"topic\"])\n",
        "    x_val = val_df[\"comments\"] if not args.use_topic else add_topic_prefix(val_df[\"comments\"], val_df[\"topic\"])\n",
        "    model = Pipeline([(\"tfidf\", TfidfVectorizer(ngram_range=(1,2))), (\"clf\", LogisticRegression(max_iter=1000, class_weight=\"balanced\"))])\n",
        "    evaluate(model, x_train, train_df[\"aspect\"], x_val, val_df[\"aspect\"], \"CLI run\")\n",
        "\n",
        "# run_cli()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}