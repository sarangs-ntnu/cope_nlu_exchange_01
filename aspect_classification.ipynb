{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Aspect Classification for Educational Feedback\n",
        "Aspect-focused notebook with baselines, prompting, cross-domain checks, and explainability."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup\n",
        "Load data, define helper utilities, and prepare aspect glossary for prompts and interpretability."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "import shap\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "\n",
        "try:\n",
        "    from sentence_transformers import SentenceTransformer\n",
        "except Exception:\n",
        "    SentenceTransformer = None"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def load_aspect_data(path=Path(\"data_feedback.xlsx\")):\n",
        "    if path.exists():\n",
        "        df = pd.read_excel(path)\n",
        "    else:\n",
        "        df = pd.DataFrame(\n",
        "            {\n",
        "                \"teacher/course\": [\"teacher\", \"course\"],\n",
        "                \"comments\": [\"great teacher\", \"great course\"],\n",
        "                \"aspect\": [\"general\", \"relevancy\"],\n",
        "            }\n",
        "        )\n",
        "    df = df.rename(columns={\"comments\": \"text\", \"teacher/course\": \"topic\"})\n",
        "    return df.dropna(subset=[\"text\", \"aspect\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Glossary and preprocessing helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "aspect_glossary = {\n",
        "    \"teaching skills\": \"Pedagogical clarity, examples, pacing, interaction.\",\n",
        "    \"behaviour\": \"Politeness, respect, supportiveness, responsiveness.\",\n",
        "    \"knowledge\": \"Depth and breadth of subject knowledge.\",\n",
        "    \"relevancy\": \"Alignment of content and practice with course goals.\",\n",
        "    \"general\": \"General praise or criticism without a specific aspect.\",\n",
        "}\n",
        "\n",
        "\n",
        "def prepend_topic(texts: List[str], topics: List[str]):\n",
        "    return [f\"[TOPIC={t}] {x}\" for x, t in zip(texts, topics)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. TF\u2013IDF baselines (word + char) with explainability"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def run_aspect_tfidf(train_df, val_df, analyzer=\"word\", prompt_topic=False):\n",
        "    X_train = train_df[\"text\"] if not prompt_topic else prepend_topic(train_df[\"text\"].tolist(), train_df[\"topic\"].tolist())\n",
        "    X_val = val_df[\"text\"] if not prompt_topic else prepend_topic(val_df[\"text\"].tolist(), val_df[\"topic\"].tolist())\n",
        "    y_train, y_val = train_df[\"aspect\"], val_df[\"aspect\"]\n",
        "\n",
        "    pipe = Pipeline(\n",
        "        [\n",
        "            (\"tfidf\", TfidfVectorizer(analyzer=analyzer, ngram_range=(1, 2))),\n",
        "            (\"clf\", LogisticRegression(max_iter=200, class_weight=\"balanced\")),\n",
        "        ]\n",
        "    )\n",
        "    pipe.fit(X_train, y_train)\n",
        "    preds = pipe.predict(X_val)\n",
        "    print(classification_report(y_val, preds, zero_division=0))\n",
        "    print(confusion_matrix(y_val, preds))\n",
        "\n",
        "    explainer = LimeTextExplainer(class_names=pipe.classes_)\n",
        "    explanation = explainer.explain_instance(X_val.iloc[0], pipe.predict_proba, num_features=8)\n",
        "    return pipe, explanation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Sentence embedding baseline (SBERT)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def run_aspect_sbert(train_df, val_df, model_name=\"all-MiniLM-L6-v2\", prompt_topic=True):\n",
        "    if SentenceTransformer is None:\n",
        "        raise ImportError(\"sentence-transformers not installed\")\n",
        "\n",
        "    model = SentenceTransformer(model_name)\n",
        "    X_train = train_df[\"text\"] if not prompt_topic else prepend_topic(train_df[\"text\"].tolist(), train_df[\"topic\"].tolist())\n",
        "    X_val = val_df[\"text\"] if not prompt_topic else prepend_topic(val_df[\"text\"].tolist(), val_df[\"topic\"].tolist())\n",
        "    y_train, y_val = train_df[\"aspect\"], val_df[\"aspect\"]\n",
        "\n",
        "    train_emb = model.encode(list(X_train), batch_size=16, show_progress_bar=True)\n",
        "    val_emb = model.encode(list(X_val), batch_size=16, show_progress_bar=True)\n",
        "\n",
        "    clf = LogisticRegression(max_iter=200, class_weight=\"balanced\")\n",
        "    clf.fit(train_emb, y_train)\n",
        "    preds = clf.predict(val_emb)\n",
        "    print(classification_report(y_val, preds, zero_division=0))\n",
        "    return clf, model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Cross-domain / cross-topic evaluation\n",
        "Train on teacher-only vs course-only to measure transfer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def cross_domain(train_df, test_df, model_fn):\n",
        "    model = model_fn(train_df, test_df)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Prompting baseline\n",
        "Zero/low-shot LLM baseline using aspect definitions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def prompt_aspect(texts: List[str], model_name=\"gpt-4o-mini\"):\n",
        "    import openai\n",
        "\n",
        "    system_msg = \"Identify the aspect label using the glossary and respond with the label only.\"\n",
        "    client = openai.OpenAI()\n",
        "    outputs = []\n",
        "    for t in texts:\n",
        "        res = client.chat.completions.create(\n",
        "            model=model_name,\n",
        "            messages=[{\"role\": \"system\", \"content\": system_msg}, {\"role\": \"user\", \"content\": t}],\n",
        "            temperature=0,\n",
        "        )\n",
        "        outputs.append(res.choices[0].message[\"content\"])\n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Explainability utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def shap_for_aspect(model, X_samples: List[str]):\n",
        "    explainer = shap.Explainer(model.predict_proba, masker=shap.maskers.Text())\n",
        "    values = explainer(X_samples)\n",
        "    shap.plots.text(values, display=False)\n",
        "    return values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Error inspection helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def error_breakdown(model, val_df, prompt_topic=False):\n",
        "    X_val = val_df[\"text\"] if not prompt_topic else prepend_topic(val_df[\"text\"].tolist(), val_df[\"topic\"].tolist())\n",
        "    preds = model.predict(X_val)\n",
        "    df_err = val_df.copy()\n",
        "    df_err[\"pred\"] = preds\n",
        "    df_err[\"correct\"] = df_err[\"pred\"] == df_err[\"aspect\"]\n",
        "    return df_err.sort_values(\"correct\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. CLI entry point"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def main_cli():\n",
        "    import argparse\n",
        "\n",
        "    parser = argparse.ArgumentParser(description=\"Aspect classification experiments\")\n",
        "    parser.add_argument(\"--model\", choices=[\"tfidf\", \"char\", \"sbert\"], default=\"tfidf\")\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    df = load_aspect_data()\n",
        "    train_df, val_df = train_test_split(df, test_size=0.25, random_state=42, stratify=df[\"aspect\"])\n",
        "\n",
        "    if args.model == \"tfidf\":\n",
        "        run_aspect_tfidf(train_df, val_df, analyzer=\"word\", prompt_topic=True)\n",
        "    elif args.model == \"char\":\n",
        "        run_aspect_tfidf(train_df, val_df, analyzer=\"char\", prompt_topic=True)\n",
        "    elif args.model == \"sbert\":\n",
        "        run_aspect_sbert(train_df, val_df)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main_cli()"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}