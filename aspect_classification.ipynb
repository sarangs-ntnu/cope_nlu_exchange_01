{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Aspect Classification Experiments\n\nGoal: assign each comment to an aspect (e.g., teaching skills, behaviour, knowledge, relevancy, general). We progress from interpretable baselines to transformers and few-shot LLMs with explainability and ethics considerations."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "import pandas as pd\nfrom pathlib import Path\n\ndf = pd.read_excel(Path('data_feedback.xlsx'))\ndf.head()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 1. Taxonomy setup and ethics\n- Define a **glossary** of aspects with concise definitions to guide models and annotators.\n- Check class frequencies; consider merging or few-shot support for rare labels.\n- Ensure the taxonomy avoids value-laden terms that could encode bias."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "aspect_glossary = {\n    'teaching skills': 'Clarity, preparation, and delivery of content',\n    'behaviour': 'Politeness, supportiveness, and interpersonal conduct',\n    'knowledge': 'Subject-matter expertise and depth',\n    'relevancy': 'Alignment of course with learner needs',\n    'general': 'Overall impressions not tied to a specific facet',\n}\naspect_glossary"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 2. Baseline: One-vs-Rest Linear Classifier\nRationale: quick baseline with high interpretability via feature weights."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.metrics import classification_report\n\nX_train, X_val, y_train, y_val = train_test_split(df['comments'], df['aspect'], test_size=0.2, stratify=df['aspect'], random_state=42)\n\ntfidf_ovr = Pipeline([('tfidf', TfidfVectorizer(ngram_range=(1,2), min_df=1)), ('clf', OneVsRestClassifier(LogisticRegression(max_iter=300, class_weight='balanced')))])\ntfidf_ovr.fit(X_train, y_train)\nprint(classification_report(y_val, tfidf_ovr.predict(X_val)))"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Feature-level explainability\nInspect the highest-weighted n-grams per class to validate alignment with glossary definitions."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "import numpy as np\nvectorizer = tfidf_ovr.named_steps['tfidf']\nclf = tfidf_ovr.named_steps['clf']\nfeature_names = np.array(vectorizer.get_feature_names_out())\nfor i, cls in enumerate(clf.classes_):\n    coefs = clf.estimators_[i].coef_[0]\n    top_indices = coefs.argsort()[-10:][::-1]\n    print(cls, feature_names[top_indices])"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 3. Intermediate: Multilingual robustness with character n-grams\nRationale: character n-grams improve robustness to typos and mixed-language expressions."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from sklearn.feature_extraction.text import TfidfVectorizer as CharTfidf\nchar_model = Pipeline([('tfidf', CharTfidf(analyzer='char', ngram_range=(3,5), min_df=1)), ('clf', OneVsRestClassifier(LogisticRegression(max_iter=300, class_weight='balanced')))])\nchar_model.fit(X_train, y_train)\nprint(classification_report(y_val, char_model.predict(X_val)))"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 4. Advanced: Transformer fine-tuning\nRationale: contextual understanding helps disambiguate overlapping aspects (e.g., teaching skills vs. knowledge)."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Skeleton for transformer training\n# from datasets import Dataset\n# from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n# model_name = 'distilbert-base-uncased'\n# tokenizer = AutoTokenizer.from_pretrained(model_name)\n# label2id = {lbl:i for i,lbl in enumerate(sorted(df['aspect'].unique()))}\n# id2label = {i:lbl for lbl,i in label2id.items()}\n# dataset = Dataset.from_pandas(df[['comments', 'aspect']])\n# dataset = dataset.map(lambda x: {'labels': label2id[x['aspect']]}, remove_columns=['aspect'])\n# dataset = dataset.map(lambda x: tokenizer(x['comments'], truncation=True), batched=True)\n# model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(label2id), id2label=id2label, label2id=label2id)\n# args = TrainingArguments(output_dir='./aspect-model', evaluation_strategy='epoch', num_train_epochs=10, learning_rate=2e-5, per_device_train_batch_size=16, load_best_model_at_end=True)\n# trainer = Trainer(model=model, args=args, train_dataset=dataset, eval_dataset=dataset, tokenizer=tokenizer)\n# trainer.train()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Explainable AI for aspects\n- Use attention/IG/SHAP to highlight tokens that map to each aspect.\n- Pair explanations with glossary definitions to validate semantic alignment."
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 5. Few-shot LLM prompting\nRationale: handle rare aspects and adapt quickly to new categories without retraining.\n- Use in-context examples per aspect.\n- Add self-consistency (vote across multiple samples) and enforce JSON schema for reliability."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Pseudocode placeholder\n# def llm_aspect_predict(text):\n#     prompt = 'You are an educational feedback classifier. Choose one aspect from the list and return JSON {label, rationale}. Aspects: teaching skills, behaviour, knowledge, relevancy, general.'\n#     return {'label': 'teaching skills', 'rationale': 'mentions teaching clarity'}"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 6. Multi-label extension (forward-looking)\nRationale: comments can mention multiple facets. Use sigmoid outputs or set-generation LLM prompts."
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 7. Error analysis & ethics\n- Confusion matrix to identify commonly confused aspects.\n- Manually inspect mispredictions with explanations; refine glossary or prompts.\n- Ethics: avoid amplifying stereotypes; communicate model uncertainty and intended use."
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 5
}