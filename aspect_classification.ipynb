{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Aspect Classification Experiments\n",
        "Classify feedback into aspects (e.g., teaching skills, behaviour, knowledge, relevancy, general) with interpretable and advanced methods plus generalization checks.\n"
      ],
      "execution_count": null,
      "outputs": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "DATA_PATH = Path('data_feedback.xlsx')\n",
        "df = pd.read_excel(DATA_PATH)\n",
        "print(df.head())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "print('Aspect label distribution:')\n",
        "print(df['aspect'].value_counts())\n",
        "print('\n",
        "Teacher/course breakdown per aspect:')\n",
        "print(pd.crosstab(df['aspect'], df['teacher/course']))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 1. Glossary + promptable definitions\n",
        "Helpful for explainability and for guiding annotators/LLM prompts.\n"
      ],
      "execution_count": null,
      "outputs": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "ASPECT_DEFINITIONS = {\n",
        "    'teaching skills': 'Pedagogy, clarity, preparedness, delivery quality.',\n",
        "    'behaviour': 'Politeness, supportiveness, attitude toward students.',\n",
        "    'knowledge': 'Subject-matter expertise and depth.',\n",
        "    'relevancy': 'Alignment of course content with needs or curriculum.',\n",
        "    'general': 'Generic praise/critique not tied to a specific trait.',\n",
        "}\n",
        "for k,v in ASPECT_DEFINITIONS.items():\n",
        "    print(f\"{k}: {v}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 2. Baseline: word TF\u2013IDF + Logistic Regression\n"
      ],
      "execution_count": null,
      "outputs": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    df['comments'], df['aspect'], test_size=0.3, random_state=42, stratify=df['aspect']\n",
        ")\n",
        "\n",
        "word_lr = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(ngram_range=(1,2), min_df=1)),\n",
        "    ('clf', LogisticRegression(max_iter=300, class_weight='balanced', multi_class='auto'))\n",
        "])\n",
        "word_lr.fit(X_train, y_train)\n",
        "preds = word_lr.predict(X_val)\n",
        "print(classification_report(y_val, preds))\n",
        "ConfusionMatrixDisplay.from_predictions(y_val, preds, normalize='true', cmap='Greens')\n",
        "plt.title('Aspect TF\u2013IDF baseline')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### SHAP explanations for aspect model\n"
      ],
      "execution_count": null,
      "outputs": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "import shap\n",
        "\n",
        "explainer = shap.LinearExplainer(word_lr.named_steps['clf'], word_lr.named_steps['tfidf'].transform(X_train))\n",
        "val_tfidf = word_lr.named_steps['tfidf'].transform(X_val)\n",
        "shap_values = explainer(val_tfidf)\n",
        "shap.plots.bar(shap_values)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 3. Character n-grams baseline\n"
      ],
      "execution_count": null,
      "outputs": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer as CharTfidf\n",
        "\n",
        "char_lr = Pipeline([\n",
        "    ('tfidf', CharTfidf(analyzer='char', ngram_range=(3,5), min_df=1)),\n",
        "    ('clf', LogisticRegression(max_iter=300, class_weight='balanced', multi_class='auto'))\n",
        "])\n",
        "char_lr.fit(X_train, y_train)\n",
        "char_preds = char_lr.predict(X_val)\n",
        "print(classification_report(y_val, char_preds))\n",
        "ConfusionMatrixDisplay.from_predictions(y_val, char_preds, normalize='true', cmap='Oranges')\n",
        "plt.title('Aspect character baseline')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 4. Hierarchical idea: detect domain then aspect\n",
        "Train a coarse teacher/course classifier first, then specialized aspect models per domain to check gains.\n"
      ],
      "execution_count": null,
      "outputs": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "coarse = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(ngram_range=(1,2))),\n",
        "    ('clf', LogisticRegression(max_iter=200))\n",
        "])\n",
        "coarse.fit(df['comments'], df['teacher/course'])\n",
        "\n",
        "teacher_mask = df['teacher/course'].str.lower().eq('teacher')\n",
        "teacher_model = word_lr.fit(df.loc[teacher_mask, 'comments'], df.loc[teacher_mask, 'aspect'])\n",
        "course_model = word_lr.fit(df.loc[~teacher_mask, 'comments'], df.loc[~teacher_mask, 'aspect'])\n",
        "\n",
        "def hierarchical_predict(text):\n",
        "    domain = coarse.predict([text])[0]\n",
        "    if domain.lower() == 'teacher':\n",
        "        return teacher_model.predict([text])[0]\n",
        "    return course_model.predict([text])[0]\n",
        "\n",
        "print('Hierarchical prediction example:', hierarchical_predict(df['comments'].iloc[0]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 5. Cross-domain holdout\n",
        "Train on teacher comments, test on course comments (and vice versa) to measure generalization.\n"
      ],
      "execution_count": null,
      "outputs": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "teacher_mask = df['teacher/course'].str.lower().eq('teacher')\n",
        "course_mask = df['teacher/course'].str.lower().eq('course')\n",
        "\n",
        "model = word_lr\n",
        "model.fit(df.loc[teacher_mask, 'comments'], df.loc[teacher_mask, 'aspect'])\n",
        "acc_teacher_to_course = accuracy_score(df.loc[course_mask, 'aspect'], model.predict(df.loc[course_mask, 'comments']))\n",
        "\n",
        "model.fit(df.loc[course_mask, 'comments'], df.loc[course_mask, 'aspect'])\n",
        "acc_course_to_teacher = accuracy_score(df.loc[teacher_mask, 'aspect'], model.predict(df.loc[teacher_mask, 'comments']))\n",
        "\n",
        "print({'teacher\u2192course': acc_teacher_to_course, 'course\u2192teacher': acc_course_to_teacher})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 6. Transformer fine-tuning\n"
      ],
      "execution_count": null,
      "outputs": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "import numpy as np\n",
        "\n",
        "model_name = 'distilbert-base-uncased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "label_list = sorted(df['aspect'].unique())\n",
        "label_to_id = {l:i for i,l in enumerate(label_list)}\n",
        "id_to_label = {i:l for l,i in label_to_id.items()}\n",
        "\n",
        "train_ds = Dataset.from_pandas(pd.DataFrame({'text': X_train, 'label': y_train.map(label_to_id)}))\n",
        "val_ds = Dataset.from_pandas(pd.DataFrame({'text': X_val, 'label': y_val.map(label_to_id)}))\n",
        "\n",
        "def tokenize(batch):\n",
        "    return tokenizer(batch['text'], padding='max_length', truncation=True, max_length=128)\n",
        "train_ds = train_ds.map(tokenize, batched=True)\n",
        "val_ds = val_ds.map(tokenize, batched=True)\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(label_list))\n",
        "args = TrainingArguments(\n",
        "    output_dir='aspect-model',\n",
        "    evaluation_strategy='epoch',\n",
        "    num_train_epochs=4,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    learning_rate=3e-5,\n",
        ")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=1)\n",
        "    from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {'accuracy': acc, 'macro_f1': f1, 'precision': precision, 'recall': recall}\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=val_ds,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "# trainer.train()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Zero-shot aspect probing\n"
      ],
      "execution_count": null,
      "outputs": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "zs = pipeline('zero-shot-classification', model='facebook/bart-large-mnli')\n",
        "labels = list(ASPECT_DEFINITIONS.keys())\n",
        "example_text = df['comments'].iloc[1]\n",
        "print(zs(example_text, candidate_labels=labels, hypothesis_template='This feedback is about {label}.'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 7. Error analysis and ethics notes\n"
      ],
      "execution_count": null,
      "outputs": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "errors = pd.DataFrame({'text': X_val, 'true': y_val, 'pred': preds})\n",
        "errors = errors[errors['true'] != errors['pred']]\n",
        "errors['length'] = errors['text'].str.len()\n",
        "errors['domain'] = errors['text'].apply(lambda t: 'teacher' if 'teacher' in t.lower() else 'course' if 'course' in t.lower() else 'unknown')\n",
        "print(errors)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 5
}